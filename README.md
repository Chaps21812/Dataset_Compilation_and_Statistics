# Dataset-Statistics

This library has been built to ease downloading and processing datasets from the S3 Siltbucket, Satsim, and SatNet. It also create statistics and can apply corrections, create COCO formatted datasets, filter datasets, 

## Usage

Primarily, users will use eihter the "data_download_tool.py" to download files, "annotation_viewer.py" to generate PNGs of annotations and full images, and "plot.ipynb" to generate plots about statistics in the whole dataset. 

### Connecting to Data Repositories

First, you must be granted access to the AWS silt S3 bucket, this contains all the annotations generated by enabled intelligence. In order to use this, I highly reccomend downloading the AWS extension on VS Code. Download the extension, then, login to the AWS ai_autonomy gov cloud and find the area labled "access keys". On the AWS extension "explorer", click the three buttons on the top right where it says "Connect to AWS". From here create a profile for your AWS connection. Then click Edit credentials, and it should lead you to a credentials page. From the AWS AI_Autonomy gov cloud, copy over the following credentials file

```
[default]
aws_access_key_id=...
aws_secret_access_key=...
aws_session_token=...
```

and the following into the config file
```
[default]
region = us-gov-west-1
```

If you plan on downloading data from the UDL, you must create an account on the UDL and find the correct download key. To do this, once you have an account and go to the store front -> UDL API-> Sky Imagery -> GET /udl/skyimagery/getFile/{id} -> Try it out -> Enter in ID 00012407-bcd5-4188-9371-0926261a6065 -> execute. From the resulting response you will find 

```
curl -X 'GET' \
  'https://unifieddatalibrary.com/udl/skyimagery/getFile/00012407-bcd5-4188-9371-0926261a6065' \
  -H 'accept: application/octet-stream' \
  -H 'Authorization: Basic [UDL Key]'
```

Copy the [UDL Key] into a file called /src/UDL_KEY.py under the variable name UDL_KEY.

### Downloading Data
Make sure to connect the repositories in the previous step to download data. If you are downloading data, find which silt directory you intend to download from using the AWS extension. (This is known not to work on ADA4, so try locally or phone a friend for a directory). Under the python notebook named "DatabaseDownloader.ipynb", there are examples of how to download data. The S3Client object requires a SILT directory, and scans and pairs all of the annotations with fits files. IF no fits files are found on SILT, then it will wait to download them from UDL. 

```
downloader = S3Client(RME04_PATH) #Initializes downloader on desired database path. Gives list of dates to download
download_directory = "/data/Dataset_Compilation_and_Statistics/Sentinel_Datasets/RME04-2025_Annotations"

#Dates displayed by the initialization of the S3 Client
RME04_dates = ["2025-05-09","2025-05-12","2025-05-14","2025-05-15","2025-05-16","2025-05-19","2025-05-21","2025-05-22","2025-05-23","2025-05-27","2025-05-28","2025-05-30","2025-06-02","2025-06-03","2025-06-04","2025-06-05","2025-06-06","2025-06-09","2025-06-10","2025-06-11","2025-06-13","2025-06-16","2025-06-17","2025-06-18","2025-06-24","2025-06-25","2025-06-26","2025-07-01","2025-07-02","2025-07-03","2025-07-07","2025-07-08","2025-07-09","2025-07-10","2025-07-11","2025-07-14","2025-07-15","2025-07-16","2025-07-17","2025-07-18","2025-07-21","2025-07-22","2025-07-23","2025-07-24","2025-07-25","2025-07-28","2025-07-29","2025-07-30","2025-07-31","2025-08-01","2025-08-04","2025-08-05","2025-08-06","2025-08-07","2025-08-08","2025-08-11","2025-08-12","2025-08-13","2025-08-14","2025-08-15","2025-08-18","2025-08-19","2025-08-20","2025-08-21","2025-08-22","2025-08-25","2025-08-26","2025-08-27","2025-08-28","2025-08-29","2025-09-02","2025-09-03","2025-09-04","2025-09-05","2025-09-08","2025-09-09","2025-09-10","2025-09-11","2025-09-12","2025-09-15","2025-09-16","2025-09-17","2025-09-18","2025-09-19","2025-09-22","2025-09-23","2025-09-24","2025-09-25","2025-09-26","2025-09-29","2025-09-30","2025-10-01","2025-10-02","2025-10-03","2025-10-06"]

#Iterating through each date and downloading data to the desired download_directory
for date in RME04_dates:
    downloader.download_annotation_dates(date, download_directory)
```

There are other download tools but I reccomend the download_annotation_dates for ease of use. Downloading data creates raw_datasets. I highly reccomend creating download scripts for repeatability instead of python notebooks. 

### Raw Datasets

Raw datasets contain the raw annotation information 

#### Preprocessing
#### Bounding Box Corrections
#### Target Injection
#### Image Chipping

### Coco Datasets

### Error Characterizer

### Create Hand Selected Datasets

### Label Star and Target Quality

### Create Calsat Dataset